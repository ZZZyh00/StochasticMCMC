######################################################################

Gaussian toy example with L1 prior

######################################################################


NOTE: Prior on the mean is the laplacian prior:


p(x) = \lambda / 2 exp(- \lambda ||x||_1)

This toy example is to estimate the mean of the data obtained from Gaussian 
multivariate distribution. The following steps were followed:

a) Generating data using 'generateData.m':
    First, we obtain observations using true pdf of a particular mean and 
    covariance. This true pdf mean choosen at random (for convenience, can also
    be pre-speficied). This mean is fixed throughout the experiment along with 
    the unit covariance and precision matrices.

b) HMC:
    We then run the HMC with a prior on the mean using 'hmc.m'. We define the
    MAP formulation that we wish to sample from in 'likelihood.m' along with its
    gradient in 'gradLikelihood.m' for HMC to iterate over the variables. 

c) We pick 'noSamples' number of run and consider the last entry to be the 
    desired sample for that particular run. This way, we obtain 'noSamples' 
    posterior sample of theta (our random paramater)

d) Using 'generatePlots.m' and known covariances, we obtain the posterior for
    mean which is also a Gaussian and compare it with the samples generated in 
    the previous state. We expect the samples to be clustered around the true
    mean of our variable of interest (mean of the data).


######################################################################
This is a single mode Gaussian model example for posterior sampling. We generate
the observed samples from a gaussian whose mean is randomly chosen from [0, 1]. 
The covariance is taken as I. 

Once these observations are generated, we would like to impose a bayesian prior 
for our parameter, mu (the mean). We take the same covariance for posterior i.e.
I. For this posterior sampling of mu, we run HMC. 

'generatePlots' shows the grouth truth posterior that can be calculated 
analytically (which is Gaussian again) and the samples generated by HMC.








%%% Commens for HMC
%
%	Description
%	SAMPLES = HMC(F, X, OPTIONS, GRADF) uses a  hybrid Monte Carlo
%	algorithm to sample from the distribution P ~ EXP(-F), where F is the
%	first argument to HMC. The Markov chain starts at the point X, and
%	the function GRADF is the gradient of the `energy' function F.
%
%	HMC(F, X, OPTIONS, GRADF, P1, P2, ...) allows additional arguments to
%	be passed to F() and GRADF().
%
%	[SAMPLES, ENERGIES, DIAGN] = HMC(F, X, OPTIONS, GRADF) also returns a
%	log of the energy values (i.e. negative log probabilities) for the
%	samples in ENERGIES and DIAGN, a structure containing diagnostic
%	information (position, momentum and acceptance threshold) for each
%	step of the chain in DIAGN.POS, DIAGN.MOM and DIAGN.ACC respectively.
%	All candidate states (including rejected ones) are stored in
%	DIAGN.POS.
%
%	[SAMPLES, ENERGIES, DIAGN] = HMC(F, X, OPTIONS, GRADF) also returns
%	the ENERGIES (i.e. negative log probabilities) corresponding to the
%	samples.  The DIAGN structure contains three fields:
%
%	POS the position vectors of the dynamic process.
%
%	MOM the momentum vectors of the dynamic process.
%
%	ACC the acceptance thresholds.
%
%	S = HMC('STATE') returns a state structure that contains the state of
%	the two random number generators RAND and RANDN and the momentum of
%	the dynamic process.  These are contained in fields  randstate,
%	randnstate and mom respectively.  The momentum state is only used for
%	a persistent momentum update.
%
%	HMC('STATE', S) resets the state to S.  If S is an integer, then it
%	is passed to RAND and RANDN and the momentum variable is randomised.
%	If S is a structure returned by HMC('STATE') then it resets the
%	generator to exactly the same state.
%
%	The optional parameters in the OPTIONS vector have the following
%	interpretations.
%
%	OPTIONS(1) is set to 1 to display the energy values and rejection
%	threshold at each step of the Markov chain. If the value is 2, then
%	the position vectors at each step are also displayed.
%
%	OPTIONS(5) is set to 1 if momentum persistence is used; default 0,
%	for complete replacement of momentum variables.
%
%	OPTIONS(7) defines the trajectory length (i.e. the number of leap-
%	frog steps at each iteration).  Minimum value 1.
%
%	OPTIONS(9) is set to 1 to check the user defined gradient function.
%
%	OPTIONS(14) is the number of samples retained from the Markov chain;
%	default 100.
%
%	OPTIONS(15) is the number of samples omitted from the start of the
%	chain; default 0.
%
%	OPTIONS(17) defines the momentum used when a persistent update of
%	(leap-frog) momentum is used.  This is bounded to the interval [0,
%	1).
%
%	OPTIONS(18) is the step size used in leap-frogs; default 1/trajectory
%	length.
%
%	See also
%	METROP
%

%	Copyright (c) Ian T Nabney (1996-2001)

% Global variable to store state of momentum variables: set by set_state
% Used to initialise variable if set
